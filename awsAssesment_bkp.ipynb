{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "path='/Users/marcosaletta/workingDir/AWSTest/device_failure_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63831a269efd4deda5dcc4fb491d47b6",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.dtypes\n",
    "df.groupby('failure').count()\n",
    "df.attribute1.value_counts() #Numeric 5\n",
    "df['diff7-8'] = df.attribute7 - df.attribute8\n",
    "#df.describe()\n",
    "df.describe()\n",
    "#df.columns\n",
    "#df.attribute9.hist(bins=10)\n",
    "##df.loc[df.attribute9>0,['failure','attribute9']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First cleaning phase\n",
    "\n",
    "looking at the date the features 7 and 8 seems to have the same distribution of value.\n",
    "\n",
    "In onder to check if the bring the same values i make the difference between the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3913e1c542f440d9a41dd0d0d947506b",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['diff7-8'] = df.attribute7 - df.attribute8\n",
    "df[['diff7-8']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['attribute7','diff7-8'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118110, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.attribute2.hist(bins=10)\n",
    "df.loc[df.attribute2==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on attribute1\n",
      "working on attribute5\n",
      "working on attribute6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a872d1e4b27a4cc2874405af275198ee",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizing columns with more values\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "for i in [1,5,6]:# range(1,10):\n",
    "    cur_col = 'attribute%s'%i\n",
    "    print('working on %s'%cur_col)\n",
    "    df[[cur_col]] = min_max_scaler.fit_transform(df[[cur_col]])\n",
    "#df = pandas.DataFrame(x_scaled)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    106.000000\n",
       "mean     101.066038\n",
       "std       76.009306\n",
       "min        5.000000\n",
       "25%       26.500000\n",
       "50%       92.000000\n",
       "75%      148.000000\n",
       "max      299.000000\n",
       "Name: date, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.device.value_counts()\n",
    "dfDevice = pd.DataFrame(df.loc[df.failure==1].device)\n",
    "#df.loc[df.failure==1].groupby('device').date.nunique()\n",
    "dfFailed = pd.merge(dfDevice,df,on='device',how='inner')\n",
    "dfFailed.groupby('device').date.nunique().describe()\n",
    "#type(dfDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042fc8f40d334dd096a1a76bab376237",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check if the failure is always the last point int the time series\n",
    "dfFailed.groupby('device').max()[['date','failure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of failure distrubution\n",
    "\n",
    "check if the distribution of the target variabile is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8057058cc14f608d76e8f5868bd40d",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfDistro = df.groupby('failure').count()[['device']]\n",
    "dfDistro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe0e1ec437447ca80ca26e7646dcc36",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    cur_col = 'attribute%s'%i\n",
    "    for lag in range(1,4):\n",
    "        curNewCol = \"%s_lag%s\"%(cur_col,lag)\n",
    "        df[[curNewCol]] = df[['attribute1']].diff(lag)\n",
    "df.fillna(0,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    124388\n",
       "0    124388\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.failure==0]\n",
    "df_minority = df[df.failure==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.failure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listNotFailed = df.loc[df.failure==0,'device']\n",
    "df.set_index('device').loc[listNotFailed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124494, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y = df['failure']\n",
    "# X = df.drop(columns=['failure','device'])\n",
    "\n",
    "Y = df_upsampled['failure']\n",
    "X = df_upsampled.drop(columns=['failure','device'])\n",
    "\n",
    "# dfDate=df.sort_values(by=['device','date'], ascending=True)\n",
    "# dfDate['day']=[i for i in range(0,dfDate.shape[0])]\n",
    "# Y = dfDate['failure']\n",
    "# X = dfDate.drop(columns=['failure','device'])\n",
    "# listFailed = df.loc[df.failure==1,'device']\n",
    "# df.set_index('device').loc[listFailed]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# sfk = StratifiedKFold(n_splits=2)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 30\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_2 = 10 \n",
    "num_input = 30\n",
    "num_classes = 1\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_2 = 10 \n",
    "num_input = 30\n",
    "num_classes = 1\n",
    "\n",
    "metrics = ['accuracy','mse']\n",
    "\n",
    "class CreateNN:\n",
    "    def __init__(self,**kargs):\n",
    "        self.activationFun = 'relu'\n",
    "        self.X = kargs['x']\n",
    "        self.Y = kargs['y']\n",
    "        self.skf = kargs['s'] \n",
    "        self.numFeatures = self.X.shape[1]\n",
    "        self.n_hidden_1 = int(self.numFeatures / 2)\n",
    "              \n",
    "    def modelDefinition(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(self.numFeatures+1, input_dim=self.numFeatures,\n",
    "                             activation=self.activationFun))\n",
    "        self.model.add(Dense(self.n_hidden_1,activation=self.activationFun))\n",
    "        self.model.add(Dense(n_hidden_2,activation=self.activationFun))\n",
    "        self.model.add(Dense(num_classes,activation='sigmoid'))\n",
    "        \n",
    "    def modelDefinitionRecurrent(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(self.numFeatures+1, input_dim=self.numFeatures,\n",
    "                             activation=self.activationFun))\n",
    "        keras.layers.SimpleRNN(1) #activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n",
    "        self.model.add(Dense(num_classes,activation='sigmoid'))\n",
    "             \n",
    "    def modelCompile(self):\n",
    "        sgd = SGD(lr=learning_rate)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=metrics)   \n",
    "        \n",
    "    def modelTrain(self):\n",
    "        print(np.unique(self.Y))\n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(self.Y),\n",
    "                                                 self.Y)\n",
    "        print('----------------->',class_weights)\n",
    "#         class_weight = {1:1,0:weightClasses}\n",
    "        history = self.model.fit(self.X, self.Y, epochs=num_steps,\n",
    "                                 batch_size=batch_size,class_weight=class_weights)\n",
    "        return history,self.model\n",
    "    \n",
    "    def modelTrainCross(self):\n",
    "        totalScores = list()\n",
    "        print(np.unique(self.Y))\n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(self.Y),\n",
    "                                                 self.Y)\n",
    "        print('----------------->',class_weights)\n",
    "        for train, test in self.skf.split(self.X,self.Y):\n",
    "#         class_weight = {1:1,0:weightClasses}\n",
    "            history = self.model.fit(self.X.iloc[train], self.Y.iloc[train], epochs=num_steps,\n",
    "                                 batch_size=batch_size,class_weight=class_weights)\n",
    "            X_test = self.X.iloc[test]\n",
    "            Y_test = self.Y.iloc[test]\n",
    "            score =self.model.evaluate(X_test,Y_test)\n",
    "            pred = self.model.predict(X_test).round()\n",
    "            print('--------------------------Partial result: ',score)\n",
    "            print('1 in test %i, 1 in pred: %i'%(np.count_nonzero(Y_test),np.count_nonzero(pred)))\n",
    "            tn, fp, fn, tp = confusion_matrix(Y_test,pred).ravel()\n",
    "            print('tn: %i, fp:%i, fn=%i,tp:%i'%(tn, fp, fn, tp))\n",
    "            totalScores.append(score[1])\n",
    "        return history,self.model, totalScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "-----------------> [1. 1.]\n",
      "Epoch 1/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.8431 - acc: 0.7670 - mean_squared_error: 0.1819\n",
      "Epoch 2/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.7935 - acc: 0.8150 - mean_squared_error: 0.1567\n",
      "Epoch 3/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.7571 - acc: 0.8221 - mean_squared_error: 0.1497\n",
      "Epoch 4/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.7824 - acc: 0.8234 - mean_squared_error: 0.1432 1s - loss: 0.8\n",
      "Epoch 5/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.7387 - acc: 0.8168 - mean_squared_error: 0.1395\n",
      "Epoch 6/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.7278 - acc: 0.8207 - mean_squared_error: 0.1369 0s - loss: 0.7282 - acc: 0.8209 - mean_squared_error\n",
      "Epoch 7/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.7187 - acc: 0.8234 - mean_squared_error: 0.1348\n",
      "Epoch 8/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.7117 - acc: 0.8246 - mean_squared_error: 0.1333\n",
      "Epoch 9/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.7040 - acc: 0.8246 - mean_squared_error: 0.1318\n",
      "Epoch 10/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6908 - acc: 0.8247 - mean_squared_error: 0.1306\n",
      "Epoch 11/100\n",
      "199020/199020 [==============================] - 3s 15us/step - loss: 0.6728 - acc: 0.8247 - mean_squared_error: 0.1305\n",
      "Epoch 12/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.7262 - acc: 0.8258 - mean_squared_error: 0.1294\n",
      "Epoch 13/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.7110 - acc: 0.8257 - mean_squared_error: 0.1277\n",
      "Epoch 14/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.7033 - acc: 0.8277 - mean_squared_error: 0.1262\n",
      "Epoch 15/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.6941 - acc: 0.8290 - mean_squared_error: 0.1248\n",
      "Epoch 16/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.6883 - acc: 0.8343 - mean_squared_error: 0.1233\n",
      "Epoch 17/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6829 - acc: 0.8383 - mean_squared_error: 0.1217\n",
      "Epoch 18/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.6784 - acc: 0.8426 - mean_squared_error: 0.1202\n",
      "Epoch 19/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.6742 - acc: 0.8417 - mean_squared_error: 0.1190\n",
      "Epoch 20/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6705 - acc: 0.8443 - mean_squared_error: 0.1177\n",
      "Epoch 21/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6664 - acc: 0.8484 - mean_squared_error: 0.1165\n",
      "Epoch 22/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.6627 - acc: 0.8498 - mean_squared_error: 0.1155\n",
      "Epoch 23/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6583 - acc: 0.8539 - mean_squared_error: 0.1146\n",
      "Epoch 24/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.6982 - acc: 0.8557 - mean_squared_error: 0.1155 \n",
      "Epoch 25/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.7184 - acc: 0.8550 - mean_squared_error: 0.1156\n",
      "Epoch 26/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.7050 - acc: 0.8551 - mean_squared_error: 0.1153 1s - loss: 0 - ETA: 0s - loss: 0.7043 - acc: 0.8553 - mean_squared_error: \n",
      "Epoch 27/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.6865 - acc: 0.8549 - mean_squared_error: 0.1150\n",
      "Epoch 28/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.6829 - acc: 0.8558 - mean_squared_error: 0.1153\n",
      "Epoch 29/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6338 - acc: 0.8447 - mean_squared_error: 0.1180\n",
      "Epoch 30/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.6837 - acc: 0.8561 - mean_squared_error: 0.1136\n",
      "Epoch 31/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5854 - acc: 0.7875 - mean_squared_error: 0.1325\n",
      "Epoch 32/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.4701 - acc: 0.8179 - mean_squared_error: 0.1233\n",
      "Epoch 33/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4992 - acc: 0.7485 - mean_squared_error: 0.1345 0s - loss: 0.5031 - acc: 0.771 - ETA: 0s - loss: 0.5027 - acc: 0.7444 - mean_squared_error: \n",
      "Epoch 34/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4367 - acc: 0.8525 - mean_squared_error: 0.1130\n",
      "Epoch 35/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.4323 - acc: 0.8616 - mean_squared_error: 0.1123\n",
      "Epoch 36/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.4681 - acc: 0.8609 - mean_squared_error: 0.1317\n",
      "Epoch 37/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4559 - acc: 0.8603 - mean_squared_error: 0.1260\n",
      "Epoch 38/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4462 - acc: 0.8598 - mean_squared_error: 0.1218\n",
      "Epoch 39/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4376 - acc: 0.8595 - mean_squared_error: 0.1180\n",
      "Epoch 40/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4304 - acc: 0.8593 - mean_squared_error: 0.1150\n",
      "Epoch 41/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4241 - acc: 0.8593 - mean_squared_error: 0.1124\n",
      "Epoch 42/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4187 - acc: 0.8628 - mean_squared_error: 0.1103\n",
      "Epoch 43/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4134 - acc: 0.8635 - mean_squared_error: 0.1082\n",
      "Epoch 44/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4096 - acc: 0.8631 - mean_squared_error: 0.1068\n",
      "Epoch 45/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4058 - acc: 0.8632 - mean_squared_error: 0.1053\n",
      "Epoch 46/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4010 - acc: 0.8632 - mean_squared_error: 0.1035\n",
      "Epoch 47/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.3969 - acc: 0.8633 - mean_squared_error: 0.1021\n",
      "Epoch 48/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3933 - acc: 0.8631 - mean_squared_error: 0.1008\n",
      "Epoch 49/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3902 - acc: 0.8629 - mean_squared_error: 0.0998\n",
      "Epoch 50/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3908 - acc: 0.8630 - mean_squared_error: 0.0995\n",
      "Epoch 51/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3871 - acc: 0.8628 - mean_squared_error: 0.0983 1s - l\n",
      "Epoch 52/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.3853 - acc: 0.8622 - mean_squared_error: 0.0977\n",
      "Epoch 53/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.3813 - acc: 0.8647 - mean_squared_error: 0.0963\n",
      "Epoch 54/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3779 - acc: 0.8670 - mean_squared_error: 0.0951\n",
      "Epoch 55/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3757 - acc: 0.8676 - mean_squared_error: 0.0944\n",
      "Epoch 56/100\n",
      "199020/199020 [==============================] - 2s 10us/step - loss: 0.3725 - acc: 0.8714 - mean_squared_error: 0.0933\n",
      "Epoch 57/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3700 - acc: 0.8717 - mean_squared_error: 0.0924\n",
      "Epoch 58/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3672 - acc: 0.8726 - mean_squared_error: 0.0916\n",
      "Epoch 59/100\n",
      "199020/199020 [==============================] - 3s 16us/step - loss: 0.3645 - acc: 0.8741 - mean_squared_error: 0.0906 0s - loss: 0.3649 - acc: 0.8741 - mean_squared_error: 0.09\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3627 - acc: 0.8758 - mean_squared_error: 0.0900\n",
      "Epoch 61/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3596 - acc: 0.8795 - mean_squared_error: 0.0890\n",
      "Epoch 62/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3574 - acc: 0.8808 - mean_squared_error: 0.0882\n",
      "Epoch 63/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3836 - acc: 0.8795 - mean_squared_error: 0.0889\n",
      "Epoch 64/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4311 - acc: 0.8769 - mean_squared_error: 0.0907\n",
      "Epoch 65/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4284 - acc: 0.8778 - mean_squared_error: 0.0898\n",
      "Epoch 66/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4259 - acc: 0.8788 - mean_squared_error: 0.0889\n",
      "Epoch 67/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4235 - acc: 0.8805 - mean_squared_error: 0.0881\n",
      "Epoch 68/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4211 - acc: 0.8818 - mean_squared_error: 0.0873\n",
      "Epoch 69/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4188 - acc: 0.8830 - mean_squared_error: 0.0865\n",
      "Epoch 70/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4165 - acc: 0.8842 - mean_squared_error: 0.0856\n",
      "Epoch 71/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4153 - acc: 0.8850 - mean_squared_error: 0.0851\n",
      "Epoch 72/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4119 - acc: 0.8856 - mean_squared_error: 0.0841\n",
      "Epoch 73/100\n",
      "199020/199020 [==============================] - 3s 18us/step - loss: 0.4097 - acc: 0.8860 - mean_squared_error: 0.0833\n",
      "Epoch 74/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4074 - acc: 0.8863 - mean_squared_error: 0.0825 0s - loss: 0.4065 - acc: 0.8861 - mean\n",
      "Epoch 75/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4054 - acc: 0.8864 - mean_squared_error: 0.0818 0s - loss: 0.4053 - acc: 0.8860 - mean_squar\n",
      "Epoch 76/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.4035 - acc: 0.8864 - mean_squared_error: 0.0811  - ETA: 0s - loss: 0.4024 - acc: 0.8865 - mean_squared_err\n",
      "Epoch 77/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.4013 - acc: 0.8870 - mean_squared_error: 0.0804\n",
      "Epoch 78/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3994 - acc: 0.8878 - mean_squared_error: 0.0797\n",
      "Epoch 79/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3976 - acc: 0.8896 - mean_squared_error: 0.0790\n",
      "Epoch 80/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3968 - acc: 0.8919 - mean_squared_error: 0.0785\n",
      "Epoch 81/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3932 - acc: 0.8926 - mean_squared_error: 0.0775\n",
      "Epoch 82/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3915 - acc: 0.8927 - mean_squared_error: 0.0769\n",
      "Epoch 83/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3914 - acc: 0.8931 - mean_squared_error: 0.0765\n",
      "Epoch 84/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3888 - acc: 0.8933 - mean_squared_error: 0.0757\n",
      "Epoch 85/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3885 - acc: 0.8936 - mean_squared_error: 0.0754\n",
      "Epoch 86/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3866 - acc: 0.8937 - mean_squared_error: 0.0748 0s - loss: 0.3867 - acc: 0.8\n",
      "Epoch 87/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3846 - acc: 0.8978 - mean_squared_error: 0.0741 1s - loss: 0.3\n",
      "Epoch 88/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3812 - acc: 0.8988 - mean_squared_error: 0.0731\n",
      "Epoch 89/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3806 - acc: 0.9021 - mean_squared_error: 0.0727\n",
      "Epoch 90/100\n",
      "199020/199020 [==============================] - 3s 15us/step - loss: 0.3819 - acc: 0.9045 - mean_squared_error: 0.0728\n",
      "Epoch 91/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3772 - acc: 0.9076 - mean_squared_error: 0.0716 1s - loss:\n",
      "Epoch 92/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3732 - acc: 0.9123 - mean_squared_error: 0.0704\n",
      "Epoch 93/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3719 - acc: 0.9146 - mean_squared_error: 0.0699 0s - loss: 0.3693 - acc: 0.9152 - mean_squ - ETA: 0s - loss: 0.3712 - acc: 0.9146 - mean_s\n",
      "Epoch 94/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3701 - acc: 0.9177 - mean_squared_error: 0.0692\n",
      "Epoch 95/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3682 - acc: 0.9214 - mean_squared_error: 0.0686 0s - loss: 0.3665 - ac\n",
      "Epoch 96/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3663 - acc: 0.9255 - mean_squared_error: 0.0679\n",
      "Epoch 97/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3649 - acc: 0.9272 - mean_squared_error: 0.0674\n",
      "Epoch 98/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3644 - acc: 0.9273 - mean_squared_error: 0.0671 1s - los - ETA: 0s - loss: 0.3631 - acc: 0.9274 - mean_squar\n",
      "Epoch 99/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3643 - acc: 0.9289 - mean_squared_error: 0.0668 0s - loss: 0.3620 - acc: 0\n",
      "Epoch 100/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3608 - acc: 0.9297 - mean_squared_error: 0.0659 0s - loss: 0.3590 - acc: 0.9\n",
      "49756/49756 [==============================] - 1s 17us/step\n",
      "--------------------------Partial result:  [0.3824303086913852, 0.920934158689637, 0.07328360789773002]\n",
      "1 in test 24878, 1 in pred: 26422\n",
      "tn: 22139, fp:2739, fn=1195,tp:23683\n",
      "Epoch 1/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3676 - acc: 0.9266 - mean_squared_error: 0.0675 1s - los\n",
      "Epoch 2/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3643 - acc: 0.9284 - mean_squared_error: 0.0664 0s - loss: 0.3648 - acc: 0.9283 - mean_squared_error: 0. - ETA: 0s - loss: 0.3641 - acc: 0.9286 - me\n",
      "Epoch 3/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3612 - acc: 0.9288 - mean_squared_error: 0.0655\n",
      "Epoch 4/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3593 - acc: 0.9293 - mean_squared_error: 0.0649\n",
      "Epoch 5/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3576 - acc: 0.9299 - mean_squared_error: 0.0643 1s - loss: 0\n",
      "Epoch 6/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3561 - acc: 0.9310 - mean_squared_error: 0.0637\n",
      "Epoch 7/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3548 - acc: 0.9318 - mean_squared_error: 0.0633\n",
      "Epoch 8/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3565 - acc: 0.9323 - mean_squared_error: 0.0636\n",
      "Epoch 9/100\n",
      "199020/199020 [==============================] - 3s 17us/step - loss: 0.3551 - acc: 0.9333 - mean_squared_error: 0.0630\n",
      "Epoch 10/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3502 - acc: 0.9346 - mean_squared_error: 0.0616\n",
      "Epoch 11/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3536 - acc: 0.9343 - mean_squared_error: 0.0625 0s - loss: 0.3523 - acc:\n",
      "Epoch 12/100\n",
      "199020/199020 [==============================] - 3s 16us/step - loss: 0.3487 - acc: 0.9356 - mean_squared_error: 0.0609\n",
      "Epoch 13/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3461 - acc: 0.9367 - mean_squared_error: 0.0602\n",
      "Epoch 14/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3438 - acc: 0.9377 - mean_squared_error: 0.0595\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3419 - acc: 0.9397 - mean_squared_error: 0.0590\n",
      "Epoch 16/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3529 - acc: 0.9371 - mean_squared_error: 0.0609\n",
      "Epoch 17/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.3409 - acc: 0.9419 - mean_squared_error: 0.0583 2s - loss: 0.3384 - acc: 0.9\n",
      "Epoch 18/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3385 - acc: 0.9431 - mean_squared_error: 0.0576 \n",
      "Epoch 19/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3365 - acc: 0.9435 - mean_squared_error: 0.0570\n",
      "Epoch 20/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3358 - acc: 0.9436 - mean_squared_error: 0.0568\n",
      "Epoch 21/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3351 - acc: 0.9444 - mean_squared_error: 0.0565\n",
      "Epoch 22/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3331 - acc: 0.9447 - mean_squared_error: 0.0560\n",
      "Epoch 23/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3313 - acc: 0.9454 - mean_squared_error: 0.0554\n",
      "Epoch 24/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.3307 - acc: 0.9458 - mean_squared_error: 0.0550\n",
      "Epoch 25/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3354 - acc: 0.9440 - mean_squared_error: 0.0564\n",
      "Epoch 26/100\n",
      " 50500/199020 [======>.......................] - ETA: 1s - loss: 0.3313 - acc: 0.9462 - mean_squared_error: 0.0551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bb923c563e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelCompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#history,model = cnn.modelTrain()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotalScores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelTrainCross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-4d69bceb135e>\u001b[0m in \u001b[0;36mmodelTrainCross\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#         class_weight = {1:1,0:weightClasses}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             history = self.model.fit(self.X.iloc[train], self.Y.iloc[train], epochs=num_steps,\n\u001b[0;32m---> 74\u001b[0;31m                                  batch_size=batch_size,class_weight=class_weights)\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "cnn=CreateNN(x=X.drop(columns=['date']),y=Y,s = skf)\n",
    "cnn.modelDefinition()\n",
    "#cnn.modelDefinitionRecurrent()\n",
    "cnn.modelCompile()\n",
    "#history,model = cnn.modelTrain()\n",
    "history, model,totalScores = cnn.modelTrainCross()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043058139164605"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(totalScores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
