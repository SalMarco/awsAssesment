{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger('')\n",
    "\n",
    "path='/Users/marcosaletta/workingDir/AWSTest/device_failure_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File and first features processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dff308fbeed4572b1612b43b7b3594d",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv(path)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 21:59:21,784 : INFO : NUmber of devices=1168\n"
     ]
    }
   ],
   "source": [
    "numDevices = df.device.nunique()\n",
    "logger.info('NUmber of devices=%i',numDevices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we see than `attribute7` and `attribute8` have the same distribution.\n",
    "\n",
    "So we make the difference between the two columns to see if they are actually identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d33afb4d7840ff89677d895adc749f",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['diff7-8'] = df.attribute7 - df.attribute8\n",
    "df[['diff7-8']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are actually identical, so we can remove one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['attribute7','diff7-8'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookin at the fatures we see that some of them have mainly zeros, while others have a more even distribution.\n",
    "\n",
    "We normalize the even ones, and keep the others original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26be1438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.attribute2.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on attribute1\n",
      "working on attribute5\n",
      "working on attribute6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eefe903ea9240e3a9fd6bff8b602cfc",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizing columns with more values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "for i in [1,5,6]:# range(1,10):\n",
    "    cur_col = 'attribute%s'%i\n",
    "    print('working on %s'%cur_col)\n",
    "    df[[cur_col]] = min_max_scaler.fit_transform(df[[cur_col]])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we have device with more failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    106.0\n",
       "mean       1.0\n",
       "std        0.0\n",
       "min        1.0\n",
       "25%        1.0\n",
       "50%        1.0\n",
       "75%        1.0\n",
       "max        1.0\n",
       "Name: device, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.failure==1,:].groupby('device')['device'].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the failure is alway associated at the max date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162116f2db6b47408a0165061bf5dd5d",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df.device.value_counts()\n",
    "dfDevice = pd.DataFrame(df.loc[df.failure==1].device)\n",
    "dfFailed = pd.merge(dfDevice,df,on='device',how='inner')\n",
    "dfFailed.groupby('device').max()[['date','failure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the time series of features' values for device with a failure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dd40e75b454320a1f9e0c0c995dd43",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listFailed = df.loc[df.failure==1,'device']\n",
    "df.set_index('device').loc[listFailed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the timeseries we can see some value rising before the failure, so it can be useful take in consideration the delta of the features with some previous days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942de8fe96fc4b7e8d4339e04f3b7157",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    cur_col = 'attribute%s'%i\n",
    "    for lag in range(1,4):\n",
    "        curNewCol = \"%s_lag%s\"%(cur_col,lag)\n",
    "        df[[curNewCol]] = df[['attribute1']].diff(lag)\n",
    "df.fillna(0,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of failure distrubution\n",
    "\n",
    "check if the distribution of the target variabile is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7dc7738f4c47528f65e9193ffff01b",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfDistro = df.groupby('failure').count()[['device']]\n",
    "numFailed=dfDistro.loc[1].device\n",
    "dfDistro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    124388\n",
       "0    124388\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.failure==0]\n",
    "df_minority = df[df.failure==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.failure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 22:41:31,967 : INFO : Append number 2\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n",
      "2019-04-07 22:41:31,988 : INFO : Append number 3\n",
      "2019-04-07 22:41:32,013 : INFO : Append number 4\n",
      "2019-04-07 22:41:32,049 : INFO : Append number 5\n",
      "2019-04-07 22:41:32,088 : INFO : Append number 6\n",
      "2019-04-07 22:41:32,126 : INFO : Append number 7\n",
      "2019-04-07 22:41:32,162 : INFO : Append number 8\n",
      "2019-04-07 22:41:32,193 : INFO : Append number 9\n",
      "2019-04-07 22:41:32,228 : INFO : Append number 10\n",
      "2019-04-07 22:41:32,260 : INFO : Append number 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "attribute1    1166\n",
       "attribute2    1166\n",
       "attribute3    1166\n",
       "attribute4    1166\n",
       "attribute5    1166\n",
       "attribute6    1166\n",
       "attribute7    1166\n",
       "attribute8    1166\n",
       "attribute9    1166\n",
       "date          1166\n",
       "device        1166\n",
       "failure       1166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDevice = pd.DataFrame(df.loc[df.failure==1].device)\n",
    "dfFailed = pd.merge(dfDevice,df,on='device',how='inner')\n",
    "df_upsampled2 = df.copy()\n",
    "propClass = int(np.round(numDevices/numFailed))\n",
    "for i in range(1,propClass):\n",
    "    logger.info('Append number %i',i+1)\n",
    "    df_upsampled2 = df_upsampled2.append(dfFailed,ignore_index=True)\n",
    "df_upsampled2.loc[df_upsampled2.failure==1,:].count()\n",
    "# dfFailed.shape\n",
    "#df_upsampled2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1881c30fc74f278a512b77886c9091",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfFailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.failure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124494, 38)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_upsampled['failure']\n",
    "X = df_upsampled.drop(columns=['failure','device'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_2 = 10 \n",
    "n_hidden_3 = 4\n",
    "num_classes = 1\n",
    "\n",
    "metrics = ['accuracy','mse']\n",
    "\n",
    "class CreateNN:\n",
    "    def __init__(self,**kargs):\n",
    "        self.activationFun = 'relu'\n",
    "        self.X = kargs['x']\n",
    "        self.Y = kargs['y']\n",
    "        self.skf = kargs['s'] \n",
    "        self.numFeatures = self.X.shape[1]\n",
    "        self.n_hidden_1 = int(self.numFeatures / 2)\n",
    "              \n",
    "    def modelDefinition(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(self.numFeatures+1, input_dim=self.numFeatures,\n",
    "                             activation=self.activationFun))\n",
    "        self.model.add(Dense(self.n_hidden_1,activation=self.activationFun))\n",
    "        self.model.add(Dense(n_hidden_2,activation=self.activationFun))\n",
    "        self.model.add(Dense(n_hidden_3,activation=self.activationFun))\n",
    "        self.model.add(Dense(num_classes,activation='sigmoid'))\n",
    "\n",
    "    def modelCompile(self):\n",
    "        sgd = SGD(lr=learning_rate)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=metrics) \n",
    "        \n",
    "    def modelEvaluation(self,X,Y,test):\n",
    "        X_test = self.X.iloc[test]\n",
    "        Y_test = self.Y.iloc[test]\n",
    "        score =self.model.evaluate(X_test,Y_test)\n",
    "        pred = self.model.predict(X_test).round()\n",
    "        logger.info('Accuracy on test for the fold %i : %f',self.foldNumber,score[1])\n",
    "        logger.info('Number of failure in test %i, number of failure in pred: %i'%(np.count_nonzero(Y_test),np.count_nonzero(pred)))\n",
    "        confList = confusion_matrix(Y_test,pred).ravel().tolist()\n",
    "        logger.info('Confusion matrix for fold %i (with the order tn,fp,fn,tp): %s',self.foldNumber,' '.join(str(i) for i in confList))\n",
    "        self.dfConfusion.loc[self.foldNumber] = confList \n",
    "        self.totalScores.append(score[1])\n",
    "    \n",
    "    def modelTrainCross(self):\n",
    "        self.totalScores = list()\n",
    "        self.foldNumber = 1\n",
    "        self.dfConfusion = pd.DataFrame(columns=['tn', 'fp', 'fn', 'tp'])\n",
    "        logger.info('Computing class weight, usefull only for unbalenced dataset')\n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(self.Y),\n",
    "                                                 self.Y)\n",
    "        logger.info('Weights for the two classes: %i and %i',class_weights[0],class_weights[1])\n",
    "        for train, test in self.skf.split(self.X,self.Y):\n",
    "            logger.info('Working on the fold %i', self.foldNumber)\n",
    "            history = self.model.fit(self.X.iloc[train], self.Y.iloc[train], epochs=num_steps,\n",
    "                                 batch_size=batch_size,class_weight=class_weights)\n",
    "            logger.info('Evaluation of the model for the fold %i',self.foldNumber)\n",
    "            self.modelEvaluation(X,Y,test)\n",
    "            self.foldNumber += 1\n",
    "        return history,self.model, self.totalScores, self.dfConfusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 16:51:24,268 : INFO : Computing class weight, usefull only for unbalenced dataset\n",
      "2019-04-07 16:51:24,285 : INFO : Weights for the two classes: 1 and 1\n",
      "2019-04-07 16:51:24,340 : INFO : Working on the fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.6312 - acc: 0.7004 - mean_squared_error: 0.2129\n",
      "Epoch 2/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6114 - acc: 0.7203 - mean_squared_error: 0.2068\n",
      "Epoch 3/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6054 - acc: 0.7091 - mean_squared_error: 0.2039\n",
      "Epoch 4/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5890 - acc: 0.7313 - mean_squared_error: 0.1945\n",
      "Epoch 5/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5907 - acc: 0.7410 - mean_squared_error: 0.1902\n",
      "Epoch 6/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5761 - acc: 0.7222 - mean_squared_error: 0.1897 0s - loss: 0.5725 - acc: 0.7309 - mean_squared_e\n",
      "Epoch 7/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5586 - acc: 0.7432 - mean_squared_error: 0.1801\n",
      "Epoch 8/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5735 - acc: 0.7007 - mean_squared_error: 0.1913\n",
      "Epoch 9/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5856 - acc: 0.6694 - mean_squared_error: 0.2003\n",
      "Epoch 10/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5714 - acc: 0.6881 - mean_squared_error: 0.1917\n",
      "Epoch 11/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5735 - acc: 0.6663 - mean_squared_error: 0.1950\n",
      "Epoch 12/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5686 - acc: 0.6664 - mean_squared_error: 0.1890\n",
      "Epoch 13/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5985 - acc: 0.6936 - mean_squared_error: 0.1763\n",
      "Epoch 14/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5845 - acc: 0.6814 - mean_squared_error: 0.1720\n",
      "Epoch 15/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5417 - acc: 0.8060 - mean_squared_error: 0.1420\n",
      "Epoch 16/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5408 - acc: 0.8193 - mean_squared_error: 0.1511\n",
      "Epoch 17/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5487 - acc: 0.8303 - mean_squared_error: 0.1575\n",
      "Epoch 18/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5372 - acc: 0.8282 - mean_squared_error: 0.1525\n",
      "Epoch 19/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5255 - acc: 0.8293 - mean_squared_error: 0.1474\n",
      "Epoch 20/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.5154 - acc: 0.8312 - mean_squared_error: 0.1432\n",
      "Epoch 21/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5070 - acc: 0.8322 - mean_squared_error: 0.1396\n",
      "Epoch 22/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4994 - acc: 0.8370 - mean_squared_error: 0.1365\n",
      "Epoch 23/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4915 - acc: 0.8390 - mean_squared_error: 0.1335\n",
      "Epoch 24/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.4854 - acc: 0.8387 - mean_squared_error: 0.1312\n",
      "Epoch 25/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4804 - acc: 0.8388 - mean_squared_error: 0.1294\n",
      "Epoch 26/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4757 - acc: 0.8385 - mean_squared_error: 0.1278\n",
      "Epoch 27/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5107 - acc: 0.8391 - mean_squared_error: 0.1283\n",
      "Epoch 28/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5449 - acc: 0.8391 - mean_squared_error: 0.1289\n",
      "Epoch 29/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5410 - acc: 0.8431 - mean_squared_error: 0.1276\n",
      "Epoch 30/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5372 - acc: 0.8443 - mean_squared_error: 0.1264\n",
      "Epoch 31/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5336 - acc: 0.8445 - mean_squared_error: 0.1253\n",
      "Epoch 32/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5300 - acc: 0.8452 - mean_squared_error: 0.1241\n",
      "Epoch 33/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5267 - acc: 0.8454 - mean_squared_error: 0.1231\n",
      "Epoch 34/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5228 - acc: 0.8458 - mean_squared_error: 0.1219\n",
      "Epoch 35/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.5194 - acc: 0.8459 - mean_squared_error: 0.1208\n",
      "Epoch 36/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5155 - acc: 0.8457 - mean_squared_error: 0.1195\n",
      "Epoch 37/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5115 - acc: 0.8458 - mean_squared_error: 0.1183\n",
      "Epoch 38/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5079 - acc: 0.8457 - mean_squared_error: 0.1171\n",
      "Epoch 39/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5038 - acc: 0.8462 - mean_squared_error: 0.1158\n",
      "Epoch 40/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5010 - acc: 0.8464 - mean_squared_error: 0.1147\n",
      "Epoch 41/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4960 - acc: 0.8467 - mean_squared_error: 0.1134\n",
      "Epoch 42/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4941 - acc: 0.8506 - mean_squared_error: 0.1123\n",
      "Epoch 43/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4881 - acc: 0.8515 - mean_squared_error: 0.1108\n",
      "Epoch 44/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4835 - acc: 0.8516 - mean_squared_error: 0.1092\n",
      "Epoch 45/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4797 - acc: 0.8520 - mean_squared_error: 0.1079\n",
      "Epoch 46/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4763 - acc: 0.8516 - mean_squared_error: 0.1067\n",
      "Epoch 47/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4986 - acc: 0.8520 - mean_squared_error: 0.1063\n",
      "Epoch 48/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5426 - acc: 0.8520 - mean_squared_error: 0.1070\n",
      "Epoch 49/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.5372 - acc: 0.8596 - mean_squared_error: 0.1052\n",
      "Epoch 50/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5320 - acc: 0.8740 - mean_squared_error: 0.1034\n",
      "Epoch 51/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4994 - acc: 0.8781 - mean_squared_error: 0.0998\n",
      "Epoch 52/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4729 - acc: 0.8806 - mean_squared_error: 0.0967\n",
      "Epoch 53/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4397 - acc: 0.8858 - mean_squared_error: 0.0937\n",
      "Epoch 54/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4341 - acc: 0.8861 - mean_squared_error: 0.0918\n",
      "Epoch 55/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4286 - acc: 0.8851 - mean_squared_error: 0.0900\n",
      "Epoch 56/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4232 - acc: 0.8847 - mean_squared_error: 0.0882\n",
      "Epoch 57/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4186 - acc: 0.8845 - mean_squared_error: 0.0866\n",
      "Epoch 58/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.4151 - acc: 0.8840 - mean_squared_error: 0.0854\n",
      "Epoch 59/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4113 - acc: 0.8853 - mean_squared_error: 0.0841\n",
      "Epoch 60/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4042 - acc: 0.8888 - mean_squared_error: 0.0817\n",
      "Epoch 61/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3993 - acc: 0.8886 - mean_squared_error: 0.0801\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3953 - acc: 0.8890 - mean_squared_error: 0.0787\n",
      "Epoch 63/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3910 - acc: 0.8908 - mean_squared_error: 0.0771\n",
      "Epoch 64/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3859 - acc: 0.8978 - mean_squared_error: 0.0753\n",
      "Epoch 65/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3821 - acc: 0.9021 - mean_squared_error: 0.0739\n",
      "Epoch 66/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3771 - acc: 0.9058 - mean_squared_error: 0.0723\n",
      "Epoch 67/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3746 - acc: 0.9058 - mean_squared_error: 0.0715\n",
      "Epoch 68/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3702 - acc: 0.9071 - mean_squared_error: 0.0699\n",
      "Epoch 69/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3679 - acc: 0.9086 - mean_squared_error: 0.0691\n",
      "Epoch 70/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3642 - acc: 0.9119 - mean_squared_error: 0.0677\n",
      "Epoch 71/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3606 - acc: 0.9164 - mean_squared_error: 0.0662 1s - l\n",
      "Epoch 72/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3550 - acc: 0.9204 - mean_squared_error: 0.0644\n",
      "Epoch 73/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3538 - acc: 0.9246 - mean_squared_error: 0.0639\n",
      "Epoch 74/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3515 - acc: 0.9286 - mean_squared_error: 0.0629\n",
      "Epoch 75/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3458 - acc: 0.9350 - mean_squared_error: 0.0610\n",
      "Epoch 76/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3389 - acc: 0.9401 - mean_squared_error: 0.0588\n",
      "Epoch 77/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3423 - acc: 0.9391 - mean_squared_error: 0.0594\n",
      "Epoch 78/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3324 - acc: 0.9425 - mean_squared_error: 0.0564\n",
      "Epoch 79/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3311 - acc: 0.9429 - mean_squared_error: 0.0558\n",
      "Epoch 80/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3331 - acc: 0.9416 - mean_squared_error: 0.0566\n",
      "Epoch 81/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3333 - acc: 0.9429 - mean_squared_error: 0.0562 0s - loss: 0.3357 - acc: 0.9421 - mean\n",
      "Epoch 82/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3222 - acc: 0.9485 - mean_squared_error: 0.0528\n",
      "Epoch 83/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3234 - acc: 0.9482 - mean_squared_error: 0.0529\n",
      "Epoch 84/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3226 - acc: 0.9477 - mean_squared_error: 0.0527\n",
      "Epoch 85/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3149 - acc: 0.9502 - mean_squared_error: 0.0505\n",
      "Epoch 86/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3139 - acc: 0.9504 - mean_squared_error: 0.0499\n",
      "Epoch 87/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3118 - acc: 0.9504 - mean_squared_error: 0.0496\n",
      "Epoch 88/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3112 - acc: 0.9507 - mean_squared_error: 0.0491\n",
      "Epoch 89/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3084 - acc: 0.9511 - mean_squared_error: 0.0486\n",
      "Epoch 90/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3080 - acc: 0.9514 - mean_squared_error: 0.0480\n",
      "Epoch 91/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3062 - acc: 0.9525 - mean_squared_error: 0.0468\n",
      "Epoch 92/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3057 - acc: 0.9519 - mean_squared_error: 0.0471\n",
      "Epoch 93/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3027 - acc: 0.9528 - mean_squared_error: 0.0463\n",
      "Epoch 94/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3037 - acc: 0.9521 - mean_squared_error: 0.0465\n",
      "Epoch 95/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3063 - acc: 0.9507 - mean_squared_error: 0.0475\n",
      "Epoch 96/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2990 - acc: 0.9532 - mean_squared_error: 0.0453\n",
      "Epoch 97/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2991 - acc: 0.9527 - mean_squared_error: 0.0455\n",
      "Epoch 98/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2964 - acc: 0.9538 - mean_squared_error: 0.0445\n",
      "Epoch 99/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2958 - acc: 0.9543 - mean_squared_error: 0.0439\n",
      "Epoch 100/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3045 - acc: 0.9519 - mean_squared_error: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 16:55:13,388 : INFO : Evaluation of the model for the fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49756/49756 [==============================] - 1s 13us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 16:55:14,418 : INFO : Accuracy on test for the fold 1 : 0.947906\n",
      "2019-04-07 16:55:14,419 : INFO : Number of failure in test 24878, number of failure in pred: 26508\n",
      "2019-04-07 16:55:14,543 : INFO : Confusion matrix for fold 1 (with the order tn,fp,fn,tp): 22767 2111 481 24397\n",
      "2019-04-07 16:55:14,552 : INFO : Working on the fold 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2947 - acc: 0.9543 - mean_squared_error: 0.0437\n",
      "Epoch 2/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3015 - acc: 0.9524 - mean_squared_error: 0.0453\n",
      "Epoch 3/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2957 - acc: 0.9539 - mean_squared_error: 0.0440\n",
      "Epoch 4/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3016 - acc: 0.9533 - mean_squared_error: 0.0444 1s - loss: 0.311\n",
      "Epoch 5/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3027 - acc: 0.9518 - mean_squared_error: 0.0455\n",
      "Epoch 6/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2996 - acc: 0.9520 - mean_squared_error: 0.0455\n",
      "Epoch 7/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3083 - acc: 0.9485 - mean_squared_error: 0.0484\n",
      "Epoch 8/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3034 - acc: 0.9509 - mean_squared_error: 0.0462\n",
      "Epoch 9/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2953 - acc: 0.9526 - mean_squared_error: 0.0447\n",
      "Epoch 10/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2979 - acc: 0.9520 - mean_squared_error: 0.0451\n",
      "Epoch 11/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2989 - acc: 0.9523 - mean_squared_error: 0.0449\n",
      "Epoch 12/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2966 - acc: 0.9523 - mean_squared_error: 0.0447\n",
      "Epoch 13/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2971 - acc: 0.9516 - mean_squared_error: 0.0452\n",
      "Epoch 14/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3102 - acc: 0.9491 - mean_squared_error: 0.0474\n",
      "Epoch 15/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2978 - acc: 0.9518 - mean_squared_error: 0.0450\n",
      "Epoch 16/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3063 - acc: 0.9480 - mean_squared_error: 0.0483\n",
      "Epoch 17/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2923 - acc: 0.9537 - mean_squared_error: 0.0433\n",
      "Epoch 18/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2907 - acc: 0.9539 - mean_squared_error: 0.0430\n",
      "Epoch 19/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2898 - acc: 0.9538 - mean_squared_error: 0.0430\n",
      "Epoch 20/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3019 - acc: 0.9529 - mean_squared_error: 0.0439\n",
      "Epoch 21/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2894 - acc: 0.9533 - mean_squared_error: 0.0434\n",
      "Epoch 22/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2855 - acc: 0.9547 - mean_squared_error: 0.0422\n",
      "Epoch 23/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2862 - acc: 0.9550 - mean_squared_error: 0.0418\n",
      "Epoch 24/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3282 - acc: 0.9521 - mean_squared_error: 0.0451\n",
      "Epoch 25/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5358 - acc: 0.9392 - mean_squared_error: 0.0578\n",
      "Epoch 26/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3841 - acc: 0.9450 - mean_squared_error: 0.0515\n",
      "Epoch 27/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2902 - acc: 0.9537 - mean_squared_error: 0.0431\n",
      "Epoch 28/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3025 - acc: 0.9520 - mean_squared_error: 0.0446\n",
      "Epoch 29/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2849 - acc: 0.9552 - mean_squared_error: 0.0418\n",
      "Epoch 30/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2832 - acc: 0.9561 - mean_squared_error: 0.0409\n",
      "Epoch 31/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2894 - acc: 0.9541 - mean_squared_error: 0.0427\n",
      "Epoch 32/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2845 - acc: 0.9560 - mean_squared_error: 0.0410\n",
      "Epoch 33/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2829 - acc: 0.9558 - mean_squared_error: 0.0412\n",
      "Epoch 34/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2819 - acc: 0.9562 - mean_squared_error: 0.0409\n",
      "Epoch 35/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2794 - acc: 0.9568 - mean_squared_error: 0.0402\n",
      "Epoch 36/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2828 - acc: 0.9568 - mean_squared_error: 0.0404\n",
      "Epoch 37/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2766 - acc: 0.9577 - mean_squared_error: 0.0395\n",
      "Epoch 38/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4969 - acc: 0.8771 - mean_squared_error: 0.1074\n",
      "Epoch 39/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.4019 - acc: 0.8759 - mean_squared_error: 0.1052\n",
      "Epoch 40/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3562 - acc: 0.8940 - mean_squared_error: 0.0898\n",
      "Epoch 41/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3312 - acc: 0.9322 - mean_squared_error: 0.0602\n",
      "Epoch 42/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.3078 - acc: 0.9476 - mean_squared_error: 0.0487\n",
      "Epoch 43/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2972 - acc: 0.9523 - mean_squared_error: 0.0450\n",
      "Epoch 44/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2951 - acc: 0.9532 - mean_squared_error: 0.0443\n",
      "Epoch 45/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2916 - acc: 0.9542 - mean_squared_error: 0.0433\n",
      "Epoch 46/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2906 - acc: 0.9541 - mean_squared_error: 0.0432\n",
      "Epoch 47/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2902 - acc: 0.9541 - mean_squared_error: 0.0432\n",
      "Epoch 48/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2911 - acc: 0.9541 - mean_squared_error: 0.0431\n",
      "Epoch 49/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2912 - acc: 0.9534 - mean_squared_error: 0.0436\n",
      "Epoch 50/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2888 - acc: 0.9537 - mean_squared_error: 0.0431\n",
      "Epoch 51/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2861 - acc: 0.9545 - mean_squared_error: 0.0422\n",
      "Epoch 52/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2871 - acc: 0.9535 - mean_squared_error: 0.0429\n",
      "Epoch 53/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2834 - acc: 0.9551 - mean_squared_error: 0.0416\n",
      "Epoch 54/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2838 - acc: 0.9546 - mean_squared_error: 0.0420\n",
      "Epoch 55/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2846 - acc: 0.9543 - mean_squared_error: 0.0422\n",
      "Epoch 56/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2826 - acc: 0.9549 - mean_squared_error: 0.0417\n",
      "Epoch 57/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2827 - acc: 0.9548 - mean_squared_error: 0.0418\n",
      "Epoch 58/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2853 - acc: 0.9542 - mean_squared_error: 0.0423\n",
      "Epoch 59/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2833 - acc: 0.9545 - mean_squared_error: 0.0420\n",
      "Epoch 60/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2814 - acc: 0.9552 - mean_squared_error: 0.0414\n",
      "Epoch 61/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2812 - acc: 0.9552 - mean_squared_error: 0.0414\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2809 - acc: 0.9552 - mean_squared_error: 0.0413\n",
      "Epoch 63/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2833 - acc: 0.9546 - mean_squared_error: 0.0419\n",
      "Epoch 64/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2803 - acc: 0.9553 - mean_squared_error: 0.0413\n",
      "Epoch 65/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2806 - acc: 0.9551 - mean_squared_error: 0.0414\n",
      "Epoch 66/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2786 - acc: 0.9559 - mean_squared_error: 0.0407\n",
      "Epoch 67/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2822 - acc: 0.9550 - mean_squared_error: 0.0416\n",
      "Epoch 68/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2816 - acc: 0.9549 - mean_squared_error: 0.0416\n",
      "Epoch 69/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2791 - acc: 0.9556 - mean_squared_error: 0.0410\n",
      "Epoch 70/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2782 - acc: 0.9560 - mean_squared_error: 0.0407\n",
      "Epoch 71/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2773 - acc: 0.9563 - mean_squared_error: 0.0404\n",
      "Epoch 72/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2774 - acc: 0.9562 - mean_squared_error: 0.0404\n",
      "Epoch 73/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2816 - acc: 0.9547 - mean_squared_error: 0.0417\n",
      "Epoch 74/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2771 - acc: 0.9560 - mean_squared_error: 0.0406\n",
      "Epoch 75/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2769 - acc: 0.9563 - mean_squared_error: 0.0402\n",
      "Epoch 76/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2795 - acc: 0.9553 - mean_squared_error: 0.0411\n",
      "Epoch 77/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2781 - acc: 0.9555 - mean_squared_error: 0.0410\n",
      "Epoch 78/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2750 - acc: 0.9566 - mean_squared_error: 0.0400\n",
      "Epoch 79/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2763 - acc: 0.9562 - mean_squared_error: 0.0404\n",
      "Epoch 80/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2767 - acc: 0.9561 - mean_squared_error: 0.0405\n",
      "Epoch 81/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2862 - acc: 0.9552 - mean_squared_error: 0.0413\n",
      "Epoch 82/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2743 - acc: 0.9566 - mean_squared_error: 0.0400\n",
      "Epoch 83/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2751 - acc: 0.9563 - mean_squared_error: 0.0402\n",
      "Epoch 84/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2750 - acc: 0.9564 - mean_squared_error: 0.0402\n",
      "Epoch 85/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2733 - acc: 0.9568 - mean_squared_error: 0.0398\n",
      "Epoch 86/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2765 - acc: 0.9559 - mean_squared_error: 0.0406\n",
      "Epoch 87/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2782 - acc: 0.9558 - mean_squared_error: 0.0406\n",
      "Epoch 88/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2768 - acc: 0.9557 - mean_squared_error: 0.0408\n",
      "Epoch 89/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2721 - acc: 0.9573 - mean_squared_error: 0.0394\n",
      "Epoch 90/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2748 - acc: 0.9565 - mean_squared_error: 0.0401\n",
      "Epoch 91/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2729 - acc: 0.9569 - mean_squared_error: 0.0397 0s - loss: 0.2740 - acc: 0.956\n",
      "Epoch 92/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2764 - acc: 0.9563 - mean_squared_error: 0.0403\n",
      "Epoch 93/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2736 - acc: 0.9568 - mean_squared_error: 0.0399\n",
      "Epoch 94/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2726 - acc: 0.9571 - mean_squared_error: 0.0396\n",
      "Epoch 95/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2711 - acc: 0.9573 - mean_squared_error: 0.0393\n",
      "Epoch 96/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2722 - acc: 0.9573 - mean_squared_error: 0.0394\n",
      "Epoch 97/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2754 - acc: 0.9562 - mean_squared_error: 0.0404\n",
      "Epoch 98/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2724 - acc: 0.9570 - mean_squared_error: 0.0396 0s - loss: 0.2718 - acc: 0.9571 - mean_squar\n",
      "Epoch 99/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2753 - acc: 0.9562 - mean_squared_error: 0.0404\n",
      "Epoch 100/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2724 - acc: 0.9570 - mean_squared_error: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 16:58:58,614 : INFO : Evaluation of the model for the fold 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49756/49756 [==============================] - 1s 12us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 16:58:59,603 : INFO : Accuracy on test for the fold 2 : 0.958276\n",
      "2019-04-07 16:58:59,604 : INFO : Number of failure in test 24878, number of failure in pred: 25986\n",
      "2019-04-07 16:58:59,729 : INFO : Confusion matrix for fold 2 (with the order tn,fp,fn,tp): 23286 1592 484 24394\n",
      "2019-04-07 16:58:59,736 : INFO : Working on the fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2714 - acc: 0.9570 - mean_squared_error: 0.0395\n",
      "Epoch 2/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2772 - acc: 0.9556 - mean_squared_error: 0.0409\n",
      "Epoch 3/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2716 - acc: 0.9571 - mean_squared_error: 0.0395 0s - loss: 0.2718 - acc: 0.9571 - mean_squared_error: \n",
      "Epoch 4/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2710 - acc: 0.9573 - mean_squared_error: 0.0394\n",
      "Epoch 5/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2707 - acc: 0.9572 - mean_squared_error: 0.0394\n",
      "Epoch 6/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2760 - acc: 0.9557 - mean_squared_error: 0.0408\n",
      "Epoch 7/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2757 - acc: 0.9566 - mean_squared_error: 0.0399\n",
      "Epoch 8/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2721 - acc: 0.9571 - mean_squared_error: 0.0396\n",
      "Epoch 9/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2712 - acc: 0.9573 - mean_squared_error: 0.0393\n",
      "Epoch 10/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2690 - acc: 0.9578 - mean_squared_error: 0.0389\n",
      "Epoch 11/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2691 - acc: 0.9577 - mean_squared_error: 0.0390\n",
      "Epoch 12/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2698 - acc: 0.9577 - mean_squared_error: 0.0391\n",
      "Epoch 13/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2701 - acc: 0.9575 - mean_squared_error: 0.0392\n",
      "Epoch 14/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2694 - acc: 0.9577 - mean_squared_error: 0.0390\n",
      "Epoch 15/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2698 - acc: 0.9577 - mean_squared_error: 0.0391\n",
      "Epoch 16/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2688 - acc: 0.9577 - mean_squared_error: 0.0389\n",
      "Epoch 17/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2693 - acc: 0.9579 - mean_squared_error: 0.0388\n",
      "Epoch 18/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2696 - acc: 0.9577 - mean_squared_error: 0.0390\n",
      "Epoch 19/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2678 - acc: 0.9583 - mean_squared_error: 0.0385\n",
      "Epoch 20/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2684 - acc: 0.9581 - mean_squared_error: 0.0387\n",
      "Epoch 21/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2672 - acc: 0.9584 - mean_squared_error: 0.0384\n",
      "Epoch 22/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2711 - acc: 0.9573 - mean_squared_error: 0.0394\n",
      "Epoch 23/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2675 - acc: 0.9584 - mean_squared_error: 0.0384\n",
      "Epoch 24/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2683 - acc: 0.9581 - mean_squared_error: 0.0387\n",
      "Epoch 25/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2676 - acc: 0.9583 - mean_squared_error: 0.0385\n",
      "Epoch 26/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2681 - acc: 0.9585 - mean_squared_error: 0.0383\n",
      "Epoch 27/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2669 - acc: 0.9585 - mean_squared_error: 0.0383\n",
      "Epoch 28/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.2670 - acc: 0.9584 - mean_squared_error: 0.0383\n",
      "Epoch 29/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2674 - acc: 0.9584 - mean_squared_error: 0.0384\n",
      "Epoch 30/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2693 - acc: 0.9580 - mean_squared_error: 0.0388 0s - loss: 0.2710 - acc: 0.9577 - mean_squared_e\n",
      "Epoch 31/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2694 - acc: 0.9582 - mean_squared_error: 0.0386\n",
      "Epoch 32/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2725 - acc: 0.9570 - mean_squared_error: 0.0397\n",
      "Epoch 33/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2648 - acc: 0.9590 - mean_squared_error: 0.0379\n",
      "Epoch 34/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2654 - acc: 0.9590 - mean_squared_error: 0.0379 0s - loss: 0.2616 - acc: 0.9592 - mean_squ\n",
      "Epoch 35/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3587 - acc: 0.9485 - mean_squared_error: 0.0479\n",
      "Epoch 36/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.6047 - acc: 0.9373 - mean_squared_error: 0.0596\n",
      "Epoch 37/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3948 - acc: 0.9490 - mean_squared_error: 0.0478\n",
      "Epoch 38/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2779 - acc: 0.9556 - mean_squared_error: 0.0411\n",
      "Epoch 39/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.2983 - acc: 0.9556 - mean_squared_error: 0.0412 1s - loss: 0.2806 - acc: 0.955 - ETA: 0s - loss: 0.2679 \n",
      "Epoch 40/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.3111 - acc: 0.9441 - mean_squared_error: 0.0513\n",
      "Epoch 41/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.5883 - acc: 0.9371 - mean_squared_error: 0.0599\n",
      "Epoch 42/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8679 - acc: 0.9231 - mean_squared_error: 0.0743\n",
      "Epoch 43/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8666 - acc: 0.9233 - mean_squared_error: 0.0741\n",
      "Epoch 44/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8668 - acc: 0.9234 - mean_squared_error: 0.0740\n",
      "Epoch 45/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8660 - acc: 0.9234 - mean_squared_error: 0.0740\n",
      "Epoch 46/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8657 - acc: 0.9235 - mean_squared_error: 0.0739\n",
      "Epoch 47/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8653 - acc: 0.9235 - mean_squared_error: 0.0738\n",
      "Epoch 48/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8653 - acc: 0.9235 - mean_squared_error: 0.0738\n",
      "Epoch 49/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8652 - acc: 0.9235 - mean_squared_error: 0.0738\n",
      "Epoch 50/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8648 - acc: 0.9236 - mean_squared_error: 0.0737\n",
      "Epoch 51/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8649 - acc: 0.9236 - mean_squared_error: 0.0738\n",
      "Epoch 52/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8646 - acc: 0.9237 - mean_squared_error: 0.0737\n",
      "Epoch 53/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8645 - acc: 0.9237 - mean_squared_error: 0.0737\n",
      "Epoch 54/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8644 - acc: 0.9237 - mean_squared_error: 0.0736\n",
      "Epoch 55/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8642 - acc: 0.9238 - mean_squared_error: 0.0736\n",
      "Epoch 56/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8641 - acc: 0.9237 - mean_squared_error: 0.0736\n",
      "Epoch 57/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8641 - acc: 0.9237 - mean_squared_error: 0.0736\n",
      "Epoch 58/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8639 - acc: 0.9238 - mean_squared_error: 0.0736\n",
      "Epoch 59/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8638 - acc: 0.9238 - mean_squared_error: 0.0736\n",
      "Epoch 60/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8637 - acc: 0.9238 - mean_squared_error: 0.0735\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8637 - acc: 0.9238 - mean_squared_error: 0.0735\n",
      "Epoch 62/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8635 - acc: 0.9238 - mean_squared_error: 0.0735\n",
      "Epoch 63/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8638 - acc: 0.9237 - mean_squared_error: 0.0736\n",
      "Epoch 64/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8635 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 65/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8634 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 66/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8633 - acc: 0.9239 - mean_squared_error: 0.0735 1s -\n",
      "Epoch 67/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8633 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 68/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8633 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 69/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8631 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 70/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8630 - acc: 0.9240 - mean_squared_error: 0.0734 0s - loss: 0.8688 - acc: 0.9237 - mean_squ\n",
      "Epoch 71/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8632 - acc: 0.9239 - mean_squared_error: 0.0735\n",
      "Epoch 72/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8643 - acc: 0.9236 - mean_squared_error: 0.0737\n",
      "Epoch 73/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8630 - acc: 0.9239 - mean_squared_error: 0.0734 1s - loss:\n",
      "Epoch 74/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8629 - acc: 0.9239 - mean_squared_error: 0.0734\n",
      "Epoch 75/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.8627 - acc: 0.9240 - mean_squared_error: 0.0734\n",
      "Epoch 76/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.8626 - acc: 0.9239 - mean_squared_error: 0.0734\n",
      "Epoch 77/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8630 - acc: 0.9238 - mean_squared_error: 0.0735\n",
      "Epoch 78/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8624 - acc: 0.9239 - mean_squared_error: 0.0734\n",
      "Epoch 79/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.8623 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 80/100\n",
      "199020/199020 [==============================] - 3s 14us/step - loss: 0.8623 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 81/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8622 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 82/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8620 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 83/100\n",
      "199020/199020 [==============================] - 3s 13us/step - loss: 0.8619 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 84/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8621 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 85/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8619 - acc: 0.9241 - mean_squared_error: 0.0733\n",
      "Epoch 86/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8619 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 87/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8621 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 88/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8618 - acc: 0.9240 - mean_squared_error: 0.0732\n",
      "Epoch 89/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8619 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 90/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8621 - acc: 0.9240 - mean_squared_error: 0.0733\n",
      "Epoch 91/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8627 - acc: 0.9236 - mean_squared_error: 0.0736 0s - loss: 0.8630 - acc: 0.9238 - mean_squared_error:  - ETA: 0s - loss: 0.8631 - acc: 0.9238 - mean\n",
      "Epoch 92/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8617 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 93/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8617 - acc: 0.9240 - mean_squared_error: 0.0732\n",
      "Epoch 94/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8614 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 95/100\n",
      "199020/199020 [==============================] - 2s 11us/step - loss: 0.8614 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 96/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8614 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 97/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8616 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 98/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8613 - acc: 0.9242 - mean_squared_error: 0.0731\n",
      "Epoch 99/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8615 - acc: 0.9241 - mean_squared_error: 0.0732\n",
      "Epoch 100/100\n",
      "199020/199020 [==============================] - 2s 12us/step - loss: 0.8622 - acc: 0.9239 - mean_squared_error: 0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:02:47,329 : INFO : Evaluation of the model for the fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49756/49756 [==============================] - 1s 12us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:02:48,305 : INFO : Accuracy on test for the fold 3 : 0.926984\n",
      "2019-04-07 17:02:48,306 : INFO : Number of failure in test 24878, number of failure in pred: 23823\n",
      "2019-04-07 17:02:48,426 : INFO : Confusion matrix for fold 3 (with the order tn,fp,fn,tp): 23589 1289 2344 22534\n",
      "2019-04-07 17:02:48,435 : INFO : Working on the fold 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3518 - acc: 0.9517 - mean_squared_error: 0.0450\n",
      "Epoch 2/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2659 - acc: 0.9585 - mean_squared_error: 0.0385\n",
      "Epoch 3/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2687 - acc: 0.9577 - mean_squared_error: 0.0392\n",
      "Epoch 4/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2667 - acc: 0.9585 - mean_squared_error: 0.0384\n",
      "Epoch 5/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2664 - acc: 0.9583 - mean_squared_error: 0.0385\n",
      "Epoch 6/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2653 - acc: 0.9584 - mean_squared_error: 0.0384 1s - loss: 0.2644 - \n",
      "Epoch 7/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2669 - acc: 0.9579 - mean_squared_error: 0.0388\n",
      "Epoch 8/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2657 - acc: 0.9581 - mean_squared_error: 0.0386\n",
      "Epoch 9/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2654 - acc: 0.9583 - mean_squared_error: 0.0385\n",
      "Epoch 10/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2651 - acc: 0.9584 - mean_squared_error: 0.0383\n",
      "Epoch 11/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2634 - acc: 0.9589 - mean_squared_error: 0.0380 0s - loss: 0.2640 - acc: 0.9585 - mean_s\n",
      "Epoch 12/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2653 - acc: 0.9584 - mean_squared_error: 0.0384\n",
      "Epoch 13/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2639 - acc: 0.9586 - mean_squared_error: 0.0382\n",
      "Epoch 14/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2635 - acc: 0.9588 - mean_squared_error: 0.0380\n",
      "Epoch 15/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2629 - acc: 0.9589 - mean_squared_error: 0.0379\n",
      "Epoch 16/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2650 - acc: 0.9583 - mean_squared_error: 0.0384\n",
      "Epoch 17/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2637 - acc: 0.9590 - mean_squared_error: 0.0379\n",
      "Epoch 18/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2627 - acc: 0.9590 - mean_squared_error: 0.0379\n",
      "Epoch 19/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2665 - acc: 0.9581 - mean_squared_error: 0.0386\n",
      "Epoch 20/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2626 - acc: 0.9590 - mean_squared_error: 0.0378\n",
      "Epoch 21/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2641 - acc: 0.9587 - mean_squared_error: 0.0381\n",
      "Epoch 22/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2634 - acc: 0.9588 - mean_squared_error: 0.0380\n",
      "Epoch 23/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2635 - acc: 0.9586 - mean_squared_error: 0.0381\n",
      "Epoch 24/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2639 - acc: 0.9586 - mean_squared_error: 0.0383\n",
      "Epoch 25/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2632 - acc: 0.9588 - mean_squared_error: 0.0380\n",
      "Epoch 26/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2644 - acc: 0.9586 - mean_squared_error: 0.0382 1s - loss: 0.261 - ETA: 0s - loss: 0.2649 - acc: 0.9587 - mean_squared_e\n",
      "Epoch 27/100\n",
      "199022/199022 [==============================] - 2s 12us/step - loss: 0.2650 - acc: 0.9582 - mean_squared_error: 0.0386\n",
      "Epoch 28/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2634 - acc: 0.9587 - mean_squared_error: 0.0381 1s - los\n",
      "Epoch 29/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2640 - acc: 0.9586 - mean_squared_error: 0.0382\n",
      "Epoch 30/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2683 - acc: 0.9579 - mean_squared_error: 0.0388\n",
      "Epoch 31/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2632 - acc: 0.9592 - mean_squared_error: 0.0376 1s - los\n",
      "Epoch 32/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2656 - acc: 0.9581 - mean_squared_error: 0.0386\n",
      "Epoch 33/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2629 - acc: 0.9589 - mean_squared_error: 0.0379\n",
      "Epoch 34/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2666 - acc: 0.9582 - mean_squared_error: 0.0385\n",
      "Epoch 35/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2615 - acc: 0.9593 - mean_squared_error: 0.0375\n",
      "Epoch 36/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2620 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 37/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2629 - acc: 0.9590 - mean_squared_error: 0.0378\n",
      "Epoch 38/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2630 - acc: 0.9591 - mean_squared_error: 0.0377\n",
      "Epoch 39/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2614 - acc: 0.9593 - mean_squared_error: 0.0376 0s - loss: 0.2621 - acc: 0.9594 - mean\n",
      "Epoch 40/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2639 - acc: 0.9585 - mean_squared_error: 0.0383\n",
      "Epoch 41/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2633 - acc: 0.9588 - mean_squared_error: 0.0381\n",
      "Epoch 42/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2628 - acc: 0.9589 - mean_squared_error: 0.0379\n",
      "Epoch 43/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2667 - acc: 0.9582 - mean_squared_error: 0.0386\n",
      "Epoch 44/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2615 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 45/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2661 - acc: 0.9583 - mean_squared_error: 0.0384\n",
      "Epoch 46/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2604 - acc: 0.9596 - mean_squared_error: 0.0373\n",
      "Epoch 47/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2684 - acc: 0.9571 - mean_squared_error: 0.0395\n",
      "Epoch 48/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2639 - acc: 0.9588 - mean_squared_error: 0.0380\n",
      "Epoch 49/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2625 - acc: 0.9590 - mean_squared_error: 0.0379\n",
      "Epoch 50/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2631 - acc: 0.9590 - mean_squared_error: 0.0378\n",
      "Epoch 51/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2615 - acc: 0.9595 - mean_squared_error: 0.0374\n",
      "Epoch 52/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2631 - acc: 0.9591 - mean_squared_error: 0.0377\n",
      "Epoch 53/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2698 - acc: 0.9574 - mean_squared_error: 0.0393\n",
      "Epoch 54/100\n",
      "199022/199022 [==============================] - 2s 12us/step - loss: 0.2639 - acc: 0.9586 - mean_squared_error: 0.0381\n",
      "Epoch 55/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2619 - acc: 0.9589 - mean_squared_error: 0.0378\n",
      "Epoch 56/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2620 - acc: 0.9591 - mean_squared_error: 0.0377\n",
      "Epoch 57/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2640 - acc: 0.9585 - mean_squared_error: 0.0382\n",
      "Epoch 58/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2599 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 59/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2616 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 60/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2644 - acc: 0.9584 - mean_squared_error: 0.0383\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2654 - acc: 0.9580 - mean_squared_error: 0.0386\n",
      "Epoch 62/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2609 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 63/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2605 - acc: 0.9594 - mean_squared_error: 0.0374\n",
      "Epoch 64/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2608 - acc: 0.9593 - mean_squared_error: 0.0374\n",
      "Epoch 65/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2608 - acc: 0.9594 - mean_squared_error: 0.0374\n",
      "Epoch 66/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2642 - acc: 0.9587 - mean_squared_error: 0.0381\n",
      "Epoch 67/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2637 - acc: 0.9588 - mean_squared_error: 0.0379\n",
      "Epoch 68/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2605 - acc: 0.9593 - mean_squared_error: 0.0375 1s - loss:\n",
      "Epoch 69/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2602 - acc: 0.9594 - mean_squared_error: 0.0374\n",
      "Epoch 70/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2602 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 71/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2616 - acc: 0.9591 - mean_squared_error: 0.0377\n",
      "Epoch 72/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2622 - acc: 0.9589 - mean_squared_error: 0.0379\n",
      "Epoch 73/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2604 - acc: 0.9594 - mean_squared_error: 0.0374\n",
      "Epoch 74/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2617 - acc: 0.9591 - mean_squared_error: 0.0376\n",
      "Epoch 75/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2618 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 76/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2602 - acc: 0.9594 - mean_squared_error: 0.0374\n",
      "Epoch 77/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2598 - acc: 0.9597 - mean_squared_error: 0.0371\n",
      "Epoch 78/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2598 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 79/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2643 - acc: 0.9585 - mean_squared_error: 0.0382 0s - loss: 0.2597 - acc: 0.9597 \n",
      "Epoch 80/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2588 - acc: 0.9597 - mean_squared_error: 0.0371\n",
      "Epoch 81/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2579 - acc: 0.9601 - mean_squared_error: 0.0368\n",
      "Epoch 82/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2608 - acc: 0.9592 - mean_squared_error: 0.0375\n",
      "Epoch 83/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2579 - acc: 0.9599 - mean_squared_error: 0.0369\n",
      "Epoch 84/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2605 - acc: 0.9593 - mean_squared_error: 0.0375\n",
      "Epoch 85/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2618 - acc: 0.9592 - mean_squared_error: 0.0375 1s - loss:\n",
      "Epoch 86/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2616 - acc: 0.9589 - mean_squared_error: 0.0378\n",
      "Epoch 87/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2604 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 88/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2607 - acc: 0.9593 - mean_squared_error: 0.0375 0s - loss: 0.2638 - acc: 0.9591 - \n",
      "Epoch 89/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2592 - acc: 0.9597 - mean_squared_error: 0.0371\n",
      "Epoch 90/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2617 - acc: 0.9592 - mean_squared_error: 0.0375\n",
      "Epoch 91/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2598 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 92/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2604 - acc: 0.9591 - mean_squared_error: 0.0376\n",
      "Epoch 93/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2596 - acc: 0.9596 - mean_squared_error: 0.0372\n",
      "Epoch 94/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2595 - acc: 0.9594 - mean_squared_error: 0.0372\n",
      "Epoch 95/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2607 - acc: 0.9592 - mean_squared_error: 0.0376\n",
      "Epoch 96/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2591 - acc: 0.9596 - mean_squared_error: 0.0372\n",
      "Epoch 97/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2601 - acc: 0.9597 - mean_squared_error: 0.0371\n",
      "Epoch 98/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2636 - acc: 0.9584 - mean_squared_error: 0.0383\n",
      "Epoch 99/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2594 - acc: 0.9595 - mean_squared_error: 0.0373\n",
      "Epoch 100/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2606 - acc: 0.9592 - mean_squared_error: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:06:32,123 : INFO : Evaluation of the model for the fold 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49754/49754 [==============================] - 1s 12us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:06:33,098 : INFO : Accuracy on test for the fold 4 : 0.963159\n",
      "2019-04-07 17:06:33,099 : INFO : Number of failure in test 24877, number of failure in pred: 25692\n",
      "2019-04-07 17:06:33,225 : INFO : Confusion matrix for fold 4 (with the order tn,fp,fn,tp): 23553 1324 509 24368\n",
      "2019-04-07 17:06:33,232 : INFO : Working on the fold 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2597 - acc: 0.9605 - mean_squared_error: 0.0365\n",
      "Epoch 2/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2670 - acc: 0.9596 - mean_squared_error: 0.0373\n",
      "Epoch 3/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2580 - acc: 0.9609 - mean_squared_error: 0.0361\n",
      "Epoch 4/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2568 - acc: 0.9610 - mean_squared_error: 0.0360\n",
      "Epoch 5/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2610 - acc: 0.9603 - mean_squared_error: 0.0366\n",
      "Epoch 6/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2589 - acc: 0.9605 - mean_squared_error: 0.0365\n",
      "Epoch 7/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2585 - acc: 0.9607 - mean_squared_error: 0.0363\n",
      "Epoch 8/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2569 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 9/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2587 - acc: 0.9605 - mean_squared_error: 0.0364\n",
      "Epoch 10/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2548 - acc: 0.9615 - mean_squared_error: 0.0355\n",
      "Epoch 11/100\n",
      "199022/199022 [==============================] - 2s 12us/step - loss: 0.2585 - acc: 0.9608 - mean_squared_error: 0.0362\n",
      "Epoch 12/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2591 - acc: 0.9602 - mean_squared_error: 0.0366\n",
      "Epoch 13/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2567 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 14/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2591 - acc: 0.9605 - mean_squared_error: 0.0365\n",
      "Epoch 15/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3500 - acc: 0.9551 - mean_squared_error: 0.0419\n",
      "Epoch 16/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2582 - acc: 0.9607 - mean_squared_error: 0.0363\n",
      "Epoch 17/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2571 - acc: 0.9609 - mean_squared_error: 0.0361\n",
      "Epoch 18/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2595 - acc: 0.9602 - mean_squared_error: 0.0366\n",
      "Epoch 19/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2588 - acc: 0.9605 - mean_squared_error: 0.0365\n",
      "Epoch 20/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2644 - acc: 0.9599 - mean_squared_error: 0.0369\n",
      "Epoch 21/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2567 - acc: 0.9611 - mean_squared_error: 0.0360\n",
      "Epoch 22/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2603 - acc: 0.9603 - mean_squared_error: 0.0365\n",
      "Epoch 23/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2581 - acc: 0.9607 - mean_squared_error: 0.0362\n",
      "Epoch 24/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2556 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 25/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2587 - acc: 0.9606 - mean_squared_error: 0.0363\n",
      "Epoch 26/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2580 - acc: 0.9607 - mean_squared_error: 0.0362\n",
      "Epoch 27/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2558 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 28/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2556 - acc: 0.9614 - mean_squared_error: 0.0357\n",
      "Epoch 29/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2581 - acc: 0.9604 - mean_squared_error: 0.0365\n",
      "Epoch 30/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2567 - acc: 0.9611 - mean_squared_error: 0.0360\n",
      "Epoch 31/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2569 - acc: 0.9610 - mean_squared_error: 0.0360\n",
      "Epoch 32/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2574 - acc: 0.9609 - mean_squared_error: 0.0360\n",
      "Epoch 33/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2578 - acc: 0.9606 - mean_squared_error: 0.0363\n",
      "Epoch 34/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2601 - acc: 0.9603 - mean_squared_error: 0.0366\n",
      "Epoch 35/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2568 - acc: 0.9608 - mean_squared_error: 0.0361\n",
      "Epoch 36/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2561 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 37/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2560 - acc: 0.9612 - mean_squared_error: 0.0359\n",
      "Epoch 38/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2569 - acc: 0.9609 - mean_squared_error: 0.0360\n",
      "Epoch 39/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2579 - acc: 0.9608 - mean_squared_error: 0.0362\n",
      "Epoch 40/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2592 - acc: 0.9605 - mean_squared_error: 0.0364\n",
      "Epoch 41/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2554 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 42/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2555 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 43/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2555 - acc: 0.9615 - mean_squared_error: 0.0356\n",
      "Epoch 44/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2563 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 45/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2572 - acc: 0.9608 - mean_squared_error: 0.0362\n",
      "Epoch 46/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2615 - acc: 0.9599 - mean_squared_error: 0.0370\n",
      "Epoch 47/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2573 - acc: 0.9607 - mean_squared_error: 0.0362 0s - loss: 0.2578 - acc:\n",
      "Epoch 48/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2595 - acc: 0.9602 - mean_squared_error: 0.0367\n",
      "Epoch 49/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2569 - acc: 0.9608 - mean_squared_error: 0.0362\n",
      "Epoch 50/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2552 - acc: 0.9613 - mean_squared_error: 0.0357 1s - loss: 0.2579 \n",
      "Epoch 51/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2584 - acc: 0.9606 - mean_squared_error: 0.0363\n",
      "Epoch 52/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2571 - acc: 0.9609 - mean_squared_error: 0.0360\n",
      "Epoch 53/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2562 - acc: 0.9613 - mean_squared_error: 0.0357 0s - loss: 0.2542 - acc: 0.9614 - mean_s\n",
      "Epoch 54/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2589 - acc: 0.9607 - mean_squared_error: 0.0363\n",
      "Epoch 55/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2567 - acc: 0.9609 - mean_squared_error: 0.0361\n",
      "Epoch 56/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2572 - acc: 0.9607 - mean_squared_error: 0.0362\n",
      "Epoch 57/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2570 - acc: 0.9609 - mean_squared_error: 0.0361 0s - loss: 0.2583 - acc: 0.9605 - mean_squared_error\n",
      "Epoch 58/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2607 - acc: 0.9598 - mean_squared_error: 0.0371\n",
      "Epoch 59/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2546 - acc: 0.9615 - mean_squared_error: 0.0355\n",
      "Epoch 60/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2563 - acc: 0.9613 - mean_squared_error: 0.0357 0s - loss: 0.2512 - \n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2570 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 62/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2561 - acc: 0.9612 - mean_squared_error: 0.0359\n",
      "Epoch 63/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2550 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 64/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2573 - acc: 0.9606 - mean_squared_error: 0.0363\n",
      "Epoch 65/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2547 - acc: 0.9615 - mean_squared_error: 0.0356\n",
      "Epoch 66/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2556 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 67/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2554 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 68/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2597 - acc: 0.9607 - mean_squared_error: 0.0363\n",
      "Epoch 69/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2559 - acc: 0.9612 - mean_squared_error: 0.0359\n",
      "Epoch 70/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2573 - acc: 0.9610 - mean_squared_error: 0.0360\n",
      "Epoch 71/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2578 - acc: 0.9605 - mean_squared_error: 0.0364\n",
      "Epoch 72/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2543 - acc: 0.9616 - mean_squared_error: 0.0355\n",
      "Epoch 73/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2574 - acc: 0.9608 - mean_squared_error: 0.0362\n",
      "Epoch 74/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2565 - acc: 0.9609 - mean_squared_error: 0.0360\n",
      "Epoch 75/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2581 - acc: 0.9604 - mean_squared_error: 0.0365\n",
      "Epoch 76/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2563 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 77/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2594 - acc: 0.9606 - mean_squared_error: 0.0364\n",
      "Epoch 78/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2557 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 79/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2688 - acc: 0.9603 - mean_squared_error: 0.0367\n",
      "Epoch 80/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2572 - acc: 0.9610 - mean_squared_error: 0.0360\n",
      "Epoch 81/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2561 - acc: 0.9611 - mean_squared_error: 0.0359\n",
      "Epoch 82/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2556 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 83/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2595 - acc: 0.9601 - mean_squared_error: 0.0367\n",
      "Epoch 84/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2539 - acc: 0.9616 - mean_squared_error: 0.0354\n",
      "Epoch 85/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2558 - acc: 0.9612 - mean_squared_error: 0.0358\n",
      "Epoch 86/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2540 - acc: 0.9617 - mean_squared_error: 0.0354\n",
      "Epoch 87/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2595 - acc: 0.9605 - mean_squared_error: 0.0365\n",
      "Epoch 88/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2552 - acc: 0.9613 - mean_squared_error: 0.0357\n",
      "Epoch 89/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3339 - acc: 0.9558 - mean_squared_error: 0.0411\n",
      "Epoch 90/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3373 - acc: 0.9557 - mean_squared_error: 0.0412\n",
      "Epoch 91/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3439 - acc: 0.9554 - mean_squared_error: 0.0416\n",
      "Epoch 92/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3379 - acc: 0.9556 - mean_squared_error: 0.0413\n",
      "Epoch 93/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3331 - acc: 0.9568 - mean_squared_error: 0.0403\n",
      "Epoch 94/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3362 - acc: 0.9558 - mean_squared_error: 0.0411\n",
      "Epoch 95/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3349 - acc: 0.9565 - mean_squared_error: 0.0405\n",
      "Epoch 96/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.3114 - acc: 0.9571 - mean_squared_error: 0.0398\n",
      "Epoch 97/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2546 - acc: 0.9618 - mean_squared_error: 0.0353\n",
      "Epoch 98/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2560 - acc: 0.9613 - mean_squared_error: 0.0358\n",
      "Epoch 99/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2552 - acc: 0.9616 - mean_squared_error: 0.0355\n",
      "Epoch 100/100\n",
      "199022/199022 [==============================] - 2s 11us/step - loss: 0.2557 - acc: 0.9613 - mean_squared_error: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:10:16,097 : INFO : Evaluation of the model for the fold 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49754/49754 [==============================] - 1s 13us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 17:10:17,094 : INFO : Accuracy on test for the fold 5 : 0.962053\n",
      "2019-04-07 17:10:17,095 : INFO : Number of failure in test 24877, number of failure in pred: 25807\n",
      "2019-04-07 17:10:17,219 : INFO : Confusion matrix for fold 5 (with the order tn,fp,fn,tp): 23468 1409 479 24398\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "cnn=CreateNN(x=X.drop(columns=['date']),y=Y,s = skf)\n",
    "cnn.modelDefinition()\n",
    "cnn.modelCompile()\n",
    "history, model,totalScores,dfConfusion = cnn.modelTrainCross()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model\n",
    "\n",
    "The mean value of the accuracy over the varius fold is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 21:31:58,097 : INFO : Average accuracy over the vaious fold: 95.17%\n"
     ]
    }
   ],
   "source": [
    "avgAcc = np.mean(totalScores)*100\n",
    "logger.info('Average accuracy over the vaious fold: {:.2f}%'.format(avgAcc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **average** confusione matrix (note is does not sum up to 100%) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tn    23332.6\n",
       "fp     1545.0\n",
       "fn      859.4\n",
       "tp    24018.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfConfusion.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
